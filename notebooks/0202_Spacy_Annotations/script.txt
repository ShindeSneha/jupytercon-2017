
[SCROLL DOWN PAST PLOT]
Let's now take a look these document objects in a big more detail. Because spacy tokenizes our text, we can grab individual tokens by indexing the document. We can also grab sequences of tokens, called spans in Spacy, by slicing the document.

[SCROLL TO SENTENCE BOUNDARY DETECTION]
These objects contain a lot of very useful annotations. As mentioned earlier, spacy performs sentence boundary detection. Calling a document's .sents method returns an iterable of sentences. Again, because spacy returns generators, it postpones doing work until we actually need results, and allows us to process individual elements of an array without needing to load everything into memory all at once. 

[SCROLL TO TOKENIZATION]
Similarly, by iterating over the document, we can get access to individual tokens. The best way to see what annotations are available at the token level is to play around with a token yourself, but lets take a look at a couple so you can get a sense of how to access them.

[SCROLL TO MORPHOLOGICAL DECOMP]
Morphemes are little bits of language, words or parts of words, that convey meaning. For instance, "un" isnt a standalone word, but as a prefix connotes the negation of whatever follows. Identifying these morphemes in natural language can be helpful, such as trying to define a new word, or determining a word's part of speech. Spacy does some morphological decomposition for us, providing word suffixes and prefixes. We'll grab these annotations from individual tokens.

[SCROLL TO POS TAGGING]
Spacy provides part of speech tagging and dependency parsing. These annotations tell us the role each word plays syntactically. Each token in the document contains these annotations, so in this example, we'll use map to grab these annotations from each token in our document. Map takes two arguments, a function and something you can iterate over, and the returns the result of the function applied to each element in the iterable as a list.

[SCROLL TO CHUNKING AND NER]
Spacy also provides annotations for spans within the document, or sequences of tokens. Sometimes we want to indicate that a sequence of tokens has a property. For example, a noun chunk is a span of tokens that collectively form some noun phrase. Recall that spacy returns generators when we ask for an iterable, so we'll convert the generator into a list to get access to all of the noun chunks in the document. Spacy also annotates spans as entities, which we'll look at by using list comprehension over the iterables of entities within the document.

[SCROLL TO TEXT SIMILARITY]
Lastly Spacy provides vector representations of tokens, spans, and documents. We'll cover this in more detail later on, but think of word embeddings as mappings from natural language to a metric space. Vectors are used to represent elements of language, and the more similar two vectors are, the more similar the underlying words, phrases, or documents are in meaning. This is a bit of an oversimplification, but its a useful mental model for now if youre unfamiliar with the concept. Spacy not only provides the vectors for tokens, spans, and documents, but also computes the similarity between any two vectors. In this example, we'll create a new document, and compute the similarity between each individual word in the document with the word "computer". Because iterating on a document gives us access to tokens, we can use the map function over the document to get similarity scores for each token. The results are then plotted.










